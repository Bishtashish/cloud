Using username "hadoop".
Authenticating with public key "imported-openssh-key"
Passphrase for key "imported-openssh-key":

       __|  __|_  )
       _|  (     /   Amazon Linux AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-ami/2018.03-release-notes/
6 package(s) needed for security, out of 8 available
Run "sudo yum update" to apply all updates.

EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR
E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R
EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R
  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R
  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R
  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R
  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR
  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R
  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R
  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R
EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R
E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R
EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR

[hadoop@ip-172-31-42-150 ~]$ hadoop fs -ls /user/
ls: `/user/': No such file or directory
[hadoop@ip-172-31-42-150 ~]$ hadoop org.apache.hadoop.examples.Grep s3://8010174                                                                                                             902bucket/ListOfInputActionRules.txt s3://8010174902bucket/Out4Grep01 .*a1.*
19/08/29 20:52:37 INFO client.RMProxy: Connecting to ResourceManager at ip-172-3                                                                                                             1-42-150.us-east-2.compute.internal/172.31.42.150:8032
19/08/29 20:52:40 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp                                                                                                             /hadoop-yarn/staging/hadoop/.staging/job_1567111879476_0001
Exception in thread "main" org.apache.hadoop.mapreduce.lib.input.InvalidInputExc                                                                                                             eption: Input path does not exist: s3://8010174902bucket/ListOfInputActionRules.                                                                                                             txt
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedL                                                                                                             istStatus(FileInputFormat.java:323)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(File                                                                                                             InputFormat.java:271)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileI                                                                                                             nputFormat.java:358)
        at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.                                                                                                             java:303)
        at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.jav                                                                                                             a:320)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitt                                                                                                             er.java:198)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInforma                                                                                                             tion.java:1844)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)
        at org.apache.hadoop.examples.Grep.run(Grep.java:78)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
        at org.apache.hadoop.examples.Grep.main(Grep.java:103)
[hadoop@ip-172-31-42-150 ~]$ hadoop org.apache.hadoop.examples.Grep s3://8010174902bucket/ListOfActionRules.txt s3://8010174902bucket/Out4Grep01 .*a1.*
19/08/29 20:53:04 INFO client.RMProxy: Connecting to ResourceManager at ip-172-3                                                                                                             1-42-150.us-east-2.compute.internal/172.31.42.150:8032
19/08/29 20:53:06 INFO input.FileInputFormat: Total input files to process : 1
19/08/29 20:53:06 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library
19/08/29 20:53:06 INFO lzo.LzoCodec: Successfully loaded & initialized native-lz                                                                                                             o library [hadoop-lzo rev 7e6c862e89bc8db32c064454a55af74ddff73bae]
19/08/29 20:53:06 INFO mapreduce.JobSubmitter: number of splits:1
19/08/29 20:53:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_15                                                                                                             67111879476_0002
19/08/29 20:53:07 INFO impl.YarnClientImpl: Submitted application application_15                                                                                                             67111879476_0002
19/08/29 20:53:07 INFO mapreduce.Job: The url to track the job: http://ip-172-31                                                                                                             -42-150.us-east-2.compute.internal:20888/proxy/application_1567111879476_0002/
19/08/29 20:53:07 INFO mapreduce.Job: Running job: job_1567111879476_0002
19/08/29 20:53:32 INFO mapreduce.Job: Job job_1567111879476_0002 running in uber                                                                                                              mode : false
19/08/29 20:53:32 INFO mapreduce.Job:  map 0% reduce 0%
19/08/29 20:53:40 INFO mapreduce.Job:  map 100% reduce 0%
19/08/29 20:53:48 INFO mapreduce.Job:  map 100% reduce 33%
19/08/29 20:53:51 INFO mapreduce.Job:  map 100% reduce 100%
19/08/29 20:53:51 INFO mapreduce.Job: Job job_1567111879476_0002 completed succe                                                                                                             ssfully
19/08/29 20:53:51 INFO mapreduce.Job: Counters: 54
        File System Counters
                FILE: Number of bytes read=169
                FILE: Number of bytes written=683909
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=108
                HDFS: Number of bytes written=448
                HDFS: Number of read operations=11
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=6
                S3: Number of bytes read=194
                S3: Number of bytes written=0
                S3: Number of read operations=0
                S3: Number of large read operations=0
                S3: Number of write operations=0
        Job Counters
                Launched map tasks=1
                Launched reduce tasks=3
                Data-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=315600
                Total time spent by all reduces in occupied slots (ms)=1827264
                Total time spent by all map tasks (ms)=6575
                Total time spent by all reduce tasks (ms)=19034
                Total vcore-milliseconds taken by all map tasks=6575
                Total vcore-milliseconds taken by all reduce tasks=19034
                Total megabyte-milliseconds taken by all map tasks=10099200
                Total megabyte-milliseconds taken by all reduce tasks=58472448
        Map-Reduce Framework
                Map input records=4
                Map output records=3
                Map output bytes=166
                Map output materialized bytes=157
                Input split bytes=108
                Combine input records=3
                Combine output records=3
                Reduce input groups=3
                Reduce shuffle bytes=157
                Reduce input records=3
                Reduce output records=3
                Spilled Records=6
                Shuffled Maps =3
                Failed Shuffles=0
                Merged Map outputs=3
                GC time elapsed (ms)=637
                CPU time spent (ms)=7610
                Physical memory (bytes) snapshot=1197326336
                Virtual memory (bytes) snapshot=17170825216
                Total committed heap usage (bytes)=1036517376
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=194
        File Output Format Counters
                Bytes Written=448
19/08/29 20:53:51 INFO client.RMProxy: Connecting to ResourceManager at ip-172-3                                                                                                             1-42-150.us-east-2.compute.internal/172.31.42.150:8032
19/08/29 20:53:51 INFO input.FileInputFormat: Total input files to process : 3
19/08/29 20:53:51 INFO mapreduce.JobSubmitter: number of splits:3
19/08/29 20:53:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_15                                                                                                             67111879476_0003
19/08/29 20:53:51 INFO impl.YarnClientImpl: Submitted application application_15                                                                                                             67111879476_0003
19/08/29 20:53:51 INFO mapreduce.Job: The url to track the job: http://ip-172-31                                                                                                             -42-150.us-east-2.compute.internal:20888/proxy/application_1567111879476_0003/
19/08/29 20:53:51 INFO mapreduce.Job: Running job: job_1567111879476_0003
19/08/29 20:54:01 INFO mapreduce.Job: Job job_1567111879476_0003 running in uber                                                                                                              mode : false
19/08/29 20:54:01 INFO mapreduce.Job:  map 0% reduce 0%
19/08/29 20:54:09 INFO mapreduce.Job:  map 33% reduce 0%
19/08/29 20:54:15 INFO mapreduce.Job:  map 67% reduce 0%
19/08/29 20:54:16 INFO mapreduce.Job:  map 100% reduce 0%
19/08/29 20:54:20 INFO mapreduce.Job:  map 100% reduce 100%
19/08/29 20:54:21 INFO mapreduce.Job: Job job_1567111879476_0003 completed succe                                                                                                             ssfully
19/08/29 20:54:21 INFO mapreduce.Job: Counters: 54
        File System Counters
                FILE: Number of bytes read=121
                FILE: Number of bytes written=681591
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=946
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=9
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=0
                S3: Number of bytes read=0
                S3: Number of bytes written=148
                S3: Number of read operations=0
                S3: Number of large read operations=0
                S3: Number of write operations=0
        Job Counters
                Launched map tasks=3
                Launched reduce tasks=1
                Data-local map tasks=3
                Total time spent by all maps in occupied slots (ms)=1310688
                Total time spent by all reduces in occupied slots (ms)=668256
                Total time spent by all map tasks (ms)=27306
                Total time spent by all reduce tasks (ms)=6961
                Total vcore-milliseconds taken by all map tasks=27306
                Total vcore-milliseconds taken by all reduce tasks=6961
                Total megabyte-milliseconds taken by all map tasks=41942016
                Total megabyte-milliseconds taken by all reduce tasks=21384192
        Map-Reduce Framework
                Map input records=3
                Map output records=3
                Map output bytes=166
                Map output materialized bytes=149
                Input split bytes=498
                Combine input records=0
                Combine output records=0
                Reduce input groups=1
                Reduce shuffle bytes=149
                Reduce input records=3
                Reduce output records=3
                Spilled Records=6
                Shuffled Maps =3
                Failed Shuffles=0
                Merged Map outputs=3
                GC time elapsed (ms)=1236
                CPU time spent (ms)=4490
                Physical memory (bytes) snapshot=2007924736
                Virtual memory (bytes) snapshot=14558744576
                Total committed heap usage (bytes)=1889533952
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=448
        File Output Format Counters
                Bytes Written=148
[hadoop@ip-172-31-42-150 ~]$ hadoop org.apache.hadoop.examples.Grep s3://8010174                                                                                                             902/Mamals.txt s3://8010174902/Out4Grep01 .*a1.*
19/08/29 20:57:44 INFO client.RMProxy: Connecting to ResourceManager at ip-172-3                                                                                                             1-42-150.us-east-2.compute.internal/172.31.42.150:8032
19/08/29 20:57:46 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp                                                                                                             /hadoop-yarn/staging/hadoop/.staging/job_1567111879476_0004
Exception in thread "main" java.io.IOException: com.amazon.ws.emr.hadoop.fs.shad                                                                                                             ed.com.amazonaws.services.s3.model.AmazonS3Exception: The specified bucket does                                                                                                              not exist (Service: Amazon S3; Status Code: 404; Error Code: NoSuchBucket; Reque                                                                                                             st ID: 61442FA8562D1614; S3 Extended Request ID: 0QRnYX7nSEMXpOvJrfGhpJ8zKi7TMRa                                                                                                             mQ1KQgHUzPyZHnFaWzfEdaa+IfajTAHPW+2+Xsi2piUs=), S3 Extended Request ID: 0QRnYX7n                                                                                                             SEMXpOvJrfGhpJ8zKi7TMRamQ1KQgHUzPyZHnFaWzfEdaa+IfajTAHPW+2+Xsi2piUs=
        at com.amazon.ws.emr.hadoop.fs.s3n.Jets3tNativeFileSystemStore.list(Jets                                                                                                             3tNativeFileSystemStore.java:286)
        at com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.getFileStatus(S3Na                                                                                                             tiveFileSystem.java:781)
        at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:64)
        at org.apache.hadoop.fs.Globber.doGlob(Globber.java:269)
        at org.apache.hadoop.fs.Globber.glob(Globber.java:148)
        at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1760)
        at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.globStatus(EmrFileSystem.ja                                                                                                             va:408)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedL                                                                                                             istStatus(FileInputFormat.java:300)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(File                                                                                                             InputFormat.java:271)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileI                                                                                                             nputFormat.java:358)
        at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.                                                                                                             java:303)
        at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.jav                                                                                                             a:320)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitt                                                                                                             er.java:198)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInforma                                                                                                             tion.java:1844)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)
        at org.apache.hadoop.examples.Grep.run(Grep.java:78)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
        at org.apache.hadoop.examples.Grep.main(Grep.java:103)
Caused by: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.Am                                                                                                             azonS3Exception: The specified bucket does not exist (Service: Amazon S3; Status                                                                                                              Code: 404; Error Code: NoSuchBucket; Request ID: 61442FA8562D1614; S3 Extended                                                                                                              Request ID: 0QRnYX7nSEMXpOvJrfGhpJ8zKi7TMRamQ1KQgHUzPyZHnFaWzfEdaa+IfajTAHPW+2+X                                                                                                             si2piUs=), S3 Extended Request ID: 0QRnYX7nSEMXpOvJrfGhpJ8zKi7TMRamQ1KQgHUzPyZHn                                                                                                             FaWzfEdaa+IfajTAHPW+2+Xsi2piUs=
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClien                                                                                                             t$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1712)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClien                                                                                                             t$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1367)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClien                                                                                                             t$RequestExecutor.executeHelper(AmazonHttpClient.java:1113)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClien                                                                                                             t$RequestExecutor.doExecute(AmazonHttpClient.java:770)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClien                                                                                                             t$RequestExecutor.executeWithTimer(AmazonHttpClient.java:744)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClien                                                                                                             t$RequestExecutor.execute(AmazonHttpClient.java:726)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClien                                                                                                             t$RequestExecutor.access$500(AmazonHttpClient.java:686)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClien                                                                                                             t$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:668)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClien                                                                                                             t.execute(AmazonHttpClient.java:532)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClien                                                                                                             t.execute(AmazonHttpClient.java:512)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3                                                                                                             Client.invoke(AmazonS3Client.java:4921)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3                                                                                                             Client.invoke(AmazonS3Client.java:4867)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3                                                                                                             Client.invoke(AmazonS3Client.java:4861)
        at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3                                                                                                             Client.listObjectsV2(AmazonS3Client.java:923)
        at com.amazon.ws.emr.hadoop.fs.s3.lite.call.ListObjectsV2Call.perform(Li                                                                                                             stObjectsV2Call.java:22)
        at com.amazon.ws.emr.hadoop.fs.s3.lite.call.ListObjectsV2Call.perform(Li                                                                                                             stObjectsV2Call.java:8)
        at com.amazon.ws.emr.hadoop.fs.s3.lite.executor.GlobalS3Executor.execute                                                                                                             (GlobalS3Executor.java:91)
        at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.invoke(AmazonS                                                                                                             3LiteClient.java:184)
        at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.listObjectsV2(                                                                                                             AmazonS3LiteClient.java:75)
        at com.amazon.ws.emr.hadoop.fs.s3n.Jets3tNativeFileSystemStore.list(Jets                                                                                                             3tNativeFileSystemStore.java:278)
        ... 22 more
[hadoop@ip-172-31-42-150 ~]$ hadoop org.apache.hadoop.examples.Grep s3://8010174902bucket/Mamals.txt s3://8010174902bucket/Out4Grep01 .*mammals.*
19/08/29 20:59:03 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-42-150.us-east-2.compute.internal/172.31.42.150:8032
19/08/29 20:59:05 INFO input.FileInputFormat: Total input files to process : 1
19/08/29 20:59:05 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library
19/08/29 20:59:05 INFO lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 7e6c862e89bc8db32c064454a55af74ddff73bae]
19/08/29 20:59:05 INFO mapreduce.JobSubmitter: number of splits:1
19/08/29 20:59:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1567111879476_0005
19/08/29 20:59:05 INFO impl.YarnClientImpl: Submitted application application_1567111879476_0005
19/08/29 20:59:05 INFO mapreduce.Job: The url to track the job: http://ip-172-31-42-150.us-east-2.compute.internal:20888/proxy/application_1567111879476_0005/
19/08/29 20:59:05 INFO mapreduce.Job: Running job: job_1567111879476_0005
19/08/29 20:59:13 INFO mapreduce.Job: Job job_1567111879476_0005 running in uber mode : false
19/08/29 20:59:13 INFO mapreduce.Job:  map 0% reduce 0%
19/08/29 20:59:22 INFO mapreduce.Job:  map 100% reduce 0%
19/08/29 20:59:29 INFO mapreduce.Job:  map 100% reduce 33%
19/08/29 20:59:32 INFO mapreduce.Job:  map 100% reduce 67%
19/08/29 20:59:33 INFO mapreduce.Job:  map 100% reduce 100%
19/08/29 20:59:33 INFO mapreduce.Job: Job job_1567111879476_0005 completed successfully
19/08/29 20:59:33 INFO mapreduce.Job: Counters: 55
        File System Counters
                FILE: Number of bytes read=2343
                FILE: Number of bytes written=688233
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=97
                HDFS: Number of bytes written=3564
                HDFS: Number of read operations=11
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=6
                S3: Number of bytes read=204438
                S3: Number of bytes written=0
                S3: Number of read operations=0
                S3: Number of large read operations=0
                S3: Number of write operations=0
        Job Counters
                Killed reduce tasks=1
                Launched map tasks=1
                Launched reduce tasks=3
                Data-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=357696
                Total time spent by all reduces in occupied slots (ms)=1554144
                Total time spent by all map tasks (ms)=7452
                Total time spent by all reduce tasks (ms)=16189
                Total vcore-milliseconds taken by all map tasks=7452
                Total vcore-milliseconds taken by all reduce tasks=16189
                Total megabyte-milliseconds taken by all map tasks=11446272
                Total megabyte-milliseconds taken by all reduce tasks=49732608
        Map-Reduce Framework
                Map input records=4300
                Map output records=39
                Map output bytes=2994
                Map output materialized bytes=2331
                Input split bytes=97
                Combine input records=39
                Combine output records=39
                Reduce input groups=39
                Reduce shuffle bytes=2331
                Reduce input records=39
                Reduce output records=39
                Spilled Records=78
                Shuffled Maps =3
                Failed Shuffles=0
                Merged Map outputs=3
                GC time elapsed (ms)=612
                CPU time spent (ms)=9840
                Physical memory (bytes) snapshot=1256275968
                Virtual memory (bytes) snapshot=17201369088
                Total committed heap usage (bytes)=1119354880
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=204438
        File Output Format Counters
                Bytes Written=3564
19/08/29 20:59:33 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-42-150.us-east-2.compute.internal/172.31.42.150:8032
Exception in thread "main" org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory s3://8010174902bucket/Out4Grep01 already exists
        at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:146)
        at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:268)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:141)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)
        at org.apache.hadoop.examples.Grep.run(Grep.java:94)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
        at org.apache.hadoop.examples.Grep.main(Grep.java:103)
[hadoop@ip-172-31-42-150 ~]$ hadoop org.apache.hadoop.examples.Grep s3://8010174902bucket/Mamals.txt s3://8010174902bucket/Out4Grep02 .*mammals.*
19/08/29 20:59:58 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-42-150.us-east-2.compute.internal/172.31.42.150:8032
19/08/29 21:00:00 INFO input.FileInputFormat: Total input files to process : 1
19/08/29 21:00:00 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library
19/08/29 21:00:00 INFO lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 7e6c862e89bc8db32c064454a55af74ddff73bae]
19/08/29 21:00:00 INFO mapreduce.JobSubmitter: number of splits:1
19/08/29 21:00:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1567111879476_0006
19/08/29 21:00:01 INFO impl.YarnClientImpl: Submitted application application_1567111879476_0006
19/08/29 21:00:01 INFO mapreduce.Job: The url to track the job: http://ip-172-31-42-150.us-east-2.compute.internal:20888/proxy/application_1567111879476_0006/
19/08/29 21:00:01 INFO mapreduce.Job: Running job: job_1567111879476_0006
19/08/29 21:00:09 INFO mapreduce.Job: Job job_1567111879476_0006 running in uber mode : false
19/08/29 21:00:09 INFO mapreduce.Job:  map 0% reduce 0%
19/08/29 21:00:18 INFO mapreduce.Job:  map 100% reduce 0%
19/08/29 21:00:24 INFO mapreduce.Job:  map 100% reduce 33%
19/08/29 21:00:28 INFO mapreduce.Job:  map 100% reduce 67%
19/08/29 21:00:29 INFO mapreduce.Job:  map 100% reduce 100%
19/08/29 21:00:29 INFO mapreduce.Job: Job job_1567111879476_0006 completed successfully
19/08/29 21:00:29 INFO mapreduce.Job: Counters: 55
        File System Counters
                FILE: Number of bytes read=2343
                FILE: Number of bytes written=688225
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=97
                HDFS: Number of bytes written=3564
                HDFS: Number of read operations=11
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=6
                S3: Number of bytes read=204438
                S3: Number of bytes written=0
                S3: Number of read operations=0
                S3: Number of large read operations=0
                S3: Number of write operations=0
        Job Counters
                Killed reduce tasks=1
                Launched map tasks=1
                Launched reduce tasks=3
                Data-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=341424
                Total time spent by all reduces in occupied slots (ms)=1506432
                Total time spent by all map tasks (ms)=7113
                Total time spent by all reduce tasks (ms)=15692
                Total vcore-milliseconds taken by all map tasks=7113
                Total vcore-milliseconds taken by all reduce tasks=15692
                Total megabyte-milliseconds taken by all map tasks=10925568
                Total megabyte-milliseconds taken by all reduce tasks=48205824
        Map-Reduce Framework
                Map input records=4300
                Map output records=39
                Map output bytes=2994
                Map output materialized bytes=2331
                Input split bytes=97
                Combine input records=39
                Combine output records=39
                Reduce input groups=39
                Reduce shuffle bytes=2331
                Reduce input records=39
                Reduce output records=39
                Spilled Records=78
                Shuffled Maps =3
                Failed Shuffles=0
                Merged Map outputs=3
                GC time elapsed (ms)=538
                CPU time spent (ms)=8960
                Physical memory (bytes) snapshot=1309818880
                Virtual memory (bytes) snapshot=17196593152
                Total committed heap usage (bytes)=1187512320
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=204438
        File Output Format Counters
                Bytes Written=3564
19/08/29 21:00:30 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-42-150.us-east-2.compute.internal/172.31.42.150:8032
19/08/29 21:00:30 INFO input.FileInputFormat: Total input files to process : 3
19/08/29 21:00:30 INFO mapreduce.JobSubmitter: number of splits:3
19/08/29 21:00:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1567111879476_0007
19/08/29 21:00:30 INFO impl.YarnClientImpl: Submitted application application_1567111879476_0007
19/08/29 21:00:30 INFO mapreduce.Job: The url to track the job: http://ip-172-31-42-150.us-east-2.compute.internal:20888/proxy/application_1567111879476_0007/
19/08/29 21:00:30 INFO mapreduce.Job: Running job: job_1567111879476_0007
19/08/29 21:00:39 INFO mapreduce.Job: Job job_1567111879476_0007 running in uber mode : false
19/08/29 21:00:39 INFO mapreduce.Job:  map 0% reduce 0%
19/08/29 21:00:47 INFO mapreduce.Job:  map 33% reduce 0%
19/08/29 21:00:53 INFO mapreduce.Job:  map 100% reduce 0%
19/08/29 21:00:57 INFO mapreduce.Job:  map 100% reduce 100%
19/08/29 21:00:58 INFO mapreduce.Job: Job job_1567111879476_0007 completed successfully
19/08/29 21:00:58 INFO mapreduce.Job: Counters: 54
        File System Counters
                FILE: Number of bytes read=1946
                FILE: Number of bytes written=685557
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=4056
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=9
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=0
                S3: Number of bytes read=0
                S3: Number of bytes written=2760
                S3: Number of read operations=0
                S3: Number of large read operations=0
                S3: Number of write operations=0
        Job Counters
                Launched map tasks=3
                Launched reduce tasks=1
                Data-local map tasks=3
                Total time spent by all maps in occupied slots (ms)=1286016
                Total time spent by all reduces in occupied slots (ms)=612192
                Total time spent by all map tasks (ms)=26792
                Total time spent by all reduce tasks (ms)=6377
                Total vcore-milliseconds taken by all map tasks=26792
                Total vcore-milliseconds taken by all reduce tasks=6377
                Total megabyte-milliseconds taken by all map tasks=41152512
                Total megabyte-milliseconds taken by all reduce tasks=19590144
        Map-Reduce Framework
                Map input records=39
                Map output records=39
                Map output bytes=2994
                Map output materialized bytes=2274
                Input split bytes=492
                Combine input records=0
                Combine output records=0
                Reduce input groups=1
                Reduce shuffle bytes=2274
                Reduce input records=39
                Reduce output records=39
                Spilled Records=78
                Shuffled Maps =3
                Failed Shuffles=0
                Merged Map outputs=3
                GC time elapsed (ms)=1252
                CPU time spent (ms)=3840
                Physical memory (bytes) snapshot=1982808064
                Virtual memory (bytes) snapshot=14568116224
                Total committed heap usage (bytes)=1811939328
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=3564
        File Output Format Counters
                Bytes Written=2760
[hadoop@ip-172-31-42-150 ~]$

