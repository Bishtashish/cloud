<<<<<NAME: Ashish Bisht>>>>>
<<<<<ID: 801168390 >>>>>

Using username "hadoop".
Authenticating with public key "imported-openssh-key"
Passphrase for key "imported-openssh-key":

       __|  __|_  )
       _|  (     /   Amazon Linux AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-ami/2018.03-release-notes/
9 package(s) needed for security, out of 17 available
Run "sudo yum update" to apply all updates.

EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR
E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R
EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R
  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R
  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R
  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R
  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR
  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R
  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R
  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R
EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R
E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R
EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR

[hadoop@ip-172-31-34-242 ~]$ aws s3 cp s3://801168390bucket/SparkAssociationRules.jar .
download: s3://801168390bucket/SparkAssociationRules.jar to ./SparkAssociationRules.jar
[hadoop@ip-172-31-34-242 ~]$ spark-submit --class org.Apriori.Driver ./SparkAssociationRules.jar s3://801168390bucket/CarData.txt MINIMUM_SUPPORT_VALUE MINIMUM_CONFIDENCE_VALUE s3://801168390bucket/SparkAssociationRulesOutput
21/03/22 00:15:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/22 00:15:29 INFO SparkContext: Running Spark version 2.4.3
21/03/22 00:15:29 INFO SparkContext: Submitted application: SparkAssociationRules
21/03/22 00:15:29 INFO SecurityManager: Changing view acls to: hadoop
21/03/22 00:15:29 INFO SecurityManager: Changing modify acls to: hadoop
21/03/22 00:15:29 INFO SecurityManager: Changing view acls groups to:
21/03/22 00:15:29 INFO SecurityManager: Changing modify acls groups to:
21/03/22 00:15:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
21/03/22 00:15:30 INFO Utils: Successfully started service 'sparkDriver' on port 33619.
21/03/22 00:15:30 INFO SparkEnv: Registering MapOutputTracker
21/03/22 00:15:30 INFO SparkEnv: Registering BlockManagerMaster
21/03/22 00:15:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/22 00:15:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/22 00:15:30 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-70c76ce4-693a-4869-9731-f3ba4c8b8ce0
21/03/22 00:15:30 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
21/03/22 00:15:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/22 00:15:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/22 00:15:31 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-34-242.us-east-2.compute.internal:4040
21/03/22 00:15:31 INFO SparkContext: Added JAR file:/home/hadoop/./SparkAssociationRules.jar at spark://ip-172-31-34-242.us-east-2.compute.internal:33619/jars/SparkAssociationRules.jar with timestamp 1572221731168
21/03/22 00:15:31 INFO Executor: Starting executor ID driver on host localhost
21/03/22 00:15:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40679.
21/03/22 00:15:31 INFO NettyBlockTransferService: Server created on ip-172-31-34-242.us-east-2.compute.internal:40679
21/03/22 00:15:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/22 00:15:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 40679, None)
21/03/22 00:15:31 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-34-242.us-east-2.compute.internal:40679 with 366.3 MB RAM, BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 40679, None)
21/03/22 00:15:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 40679, None)
21/03/22 00:15:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 40679, None)
21/03/22 00:15:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 230.6 KB, free 366.1 MB)
21/03/22 00:15:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.7 KB, free 366.1 MB)
21/03/22 00:15:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ip-172-31-34-242.us-east-2.compute.internal:40679 (size: 22.7 KB, free: 366.3 MB)
21/03/22 00:15:33 INFO SparkContext: Created broadcast 0 from textFile at Driver.scala:18
Exception in thread "main" java.lang.NumberFormatException: For input string: "MINIMUM_SUPPORT_VALUE"
        at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
        at java.lang.Integer.parseInt(Integer.java:580)
        at java.lang.Integer.parseInt(Integer.java:615)
        at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
        at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
        at org.Apriori.Driver$.main(Driver.scala:21)
        at org.Apriori.Driver.main(Driver.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:857)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:932)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:941)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/03/22 00:15:34 INFO SparkContext: Invoking stop() from shutdown hook
21/03/22 00:15:34 INFO SparkUI: Stopped Spark web UI at http://ip-172-31-34-242.us-east-2.compute.internal:4040
21/03/22 00:15:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/22 00:15:34 INFO MemoryStore: MemoryStore cleared
21/03/22 00:15:34 INFO BlockManager: BlockManager stopped
21/03/22 00:15:34 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/22 00:15:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/22 00:15:34 INFO SparkContext: Successfully stopped SparkContext
21/03/22 00:15:34 INFO ShutdownHookManager: Shutdown hook called
21/03/22 00:15:34 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-707a0fac-9a2d-4de7-981a-5559159c28fe
21/03/22 00:15:34 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-760fd4d8-d998-4efd-998f-c14cd0b81332
[hadoop@ip-172-31-34-242 ~]$
[hadoop@ip-172-31-34-242 ~]$ spark-submit --class org.Apriori.Driver ./SparkAssociationRules.jar s3://801168390bucket/SampleData.txt MINIMUM_SUPPORT_VALUE MINIMUM_CONFIDENCE_VALUE s3://801168390bucket/SparkAssociationRulesOutput
21/03/22 00:20:05 INFO SparkContext: Running Spark version 2.4.3
21/03/22 00:20:06 INFO SparkContext: Submitted application: SparkAssociationRules
21/03/22 00:20:06 INFO SecurityManager: Changing view acls to: hadoop
21/03/22 00:20:06 INFO SecurityManager: Changing modify acls to: hadoop
21/03/22 00:20:06 INFO SecurityManager: Changing view acls groups to:
21/03/22 00:20:06 INFO SecurityManager: Changing modify acls groups to:
21/03/22 00:20:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
21/03/22 00:20:06 INFO Utils: Successfully started service 'sparkDriver' on port 39769.
21/03/22 00:20:06 INFO SparkEnv: Registering MapOutputTracker
21/03/22 00:20:07 INFO SparkEnv: Registering BlockManagerMaster
21/03/22 00:20:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/22 00:20:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/22 00:20:07 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-309f7a35-bf54-4d2f-abf2-3a5142602f50
21/03/22 00:20:07 INFO MemoryStore: MemoryStore started with capacity 424.4 MB
21/03/22 00:20:07 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/22 00:20:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/22 00:20:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-34-242.us-east-2.compute.internal:4040
21/03/22 00:20:07 INFO SparkContext: Added JAR file:/home/hadoop/./SparkAssociationRules.jar at spark://ip-172-31-34-242.us-east-2.compute.internal:39769/jars/SparkAssociationRules.jar with timestamp 1572222007500
21/03/22 00:20:07 INFO Executor: Starting executor ID driver on host localhost
21/03/22 00:20:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38175.
21/03/22 00:20:07 INFO NettyBlockTransferService: Server created on ip-172-31-34-242.us-east-2.compute.internal:38175
21/03/22 00:20:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/22 00:20:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 38175, None)
21/03/22 00:20:07 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-34-242.us-east-2.compute.internal:38175 with 424.4 MB RAM, BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 38175, None)
21/03/22 00:20:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 38175, None)
21/03/22 00:20:07 INFO BlockManager: external shuffle service port = 7337
21/03/22 00:20:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 38175, None)
21/03/22 00:20:09 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/local-1572222007589
21/03/22 00:20:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 237.8 KB, free 424.2 MB)
21/03/22 00:20:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.2 KB, free 424.2 MB)
21/03/22 00:20:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ip-172-31-34-242.us-east-2.compute.internal:38175 (size: 24.2 KB, free: 424.4 MB)
21/03/22 00:20:10 INFO SparkContext: Created broadcast 0 from textFile at Driver.scala:18
Exception in thread "main" java.lang.NumberFormatException: For input string: "MINIMUM_SUPPORT_VALUE"
        at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
        at java.lang.Integer.parseInt(Integer.java:580)
        at java.lang.Integer.parseInt(Integer.java:615)
        at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
        at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
        at org.Apriori.Driver$.main(Driver.scala:21)
        at org.Apriori.Driver.main(Driver.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:857)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:932)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:941)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/03/22 00:20:10 INFO SparkContext: Invoking stop() from shutdown hook
21/03/22 00:20:10 INFO SparkUI: Stopped Spark web UI at http://ip-172-31-34-242.us-east-2.compute.internal:4040
21/03/22 00:20:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/22 00:20:10 INFO MemoryStore: MemoryStore cleared
21/03/22 00:20:10 INFO BlockManager: BlockManager stopped
21/03/22 00:20:10 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/22 00:20:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/22 00:20:10 INFO SparkContext: Successfully stopped SparkContext
21/03/22 00:20:10 INFO ShutdownHookManager: Shutdown hook called
21/03/22 00:20:10 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-63cf3efa-2780-48da-aade-6ca13bd0e09e
21/03/22 00:20:10 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-a512eed3-d1b9-4b82-8e28-731756b5212f
[hadoop@ip-172-31-34-242 ~]$
[hadoop@ip-172-31-34-242 ~]$ spark-submit --class org.Apriori.Driver ./SparkAssociationRules.jar s3://801168390bucket/SampleData.txt MINIMUM_SUPPORT_VALUE MINIMUM_CONFIDENCE_VALUE s3://801168390bucket/SparkAssociationRulesOutput
21/03/22 00:20:05 INFO SparkContext: Running Spark version 2.4.3
21/03/22 00:20:06 INFO SparkContext: Submitted application: SparkAssociationRules
21/03/22 00:20:06 INFO SecurityManager: Changing view acls to: hadoop
21/03/22 00:20:06 INFO SecurityManager: Changing modify acls to: hadoop
21/03/22 00:20:06 INFO SecurityManager: Changing view acls groups to:
21/03/22 00:20:06 INFO SecurityManager: Changing modify acls groups to:
21/03/22 00:20:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
21/03/22 00:20:06 INFO Utils: Successfully started service 'sparkDriver' on port 39769.
21/03/22 00:20:06 INFO SparkEnv: Registering MapOutputTracker
21/03/22 00:20:07 INFO SparkEnv: Registering BlockManagerMaster
21/03/22 00:20:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/03/22 00:20:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/03/22 00:20:07 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-309f7a35-bf54-4d2f-abf2-3a5142602f50
21/03/22 00:20:07 INFO MemoryStore: MemoryStore started with capacity 424.4 MB
21/03/22 00:20:07 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/22 00:20:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/22 00:20:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-34-242.us-east-2.compute.internal:4040
21/03/22 00:20:07 INFO SparkContext: Added JAR file:/home/hadoop/./SparkAssociationRules.jar at spark://ip-172-31-34-242.us-east-2.compute.internal:39769/jars/SparkAssociationRules.jar with timestamp 1572222007500
21/03/22 00:20:07 INFO Executor: Starting executor ID driver on host localhost
21/03/22 00:20:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38175.
21/03/22 00:20:07 INFO NettyBlockTransferService: Server created on ip-172-31-34-242.us-east-2.compute.internal:38175
21/03/22 00:20:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/03/22 00:20:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 38175, None)
21/03/22 00:20:07 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-34-242.us-east-2.compute.internal:38175 with 424.4 MB RAM, BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 38175, None)
21/03/22 00:20:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 38175, None)
21/03/22 00:20:07 INFO BlockManager: external shuffle service port = 7337
21/03/22 00:20:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-34-242.us-east-2.compute.internal, 38175, None)
21/03/22 00:20:09 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/local-1572222007589
21/03/22 00:20:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 237.8 KB, free 424.2 MB)
21/03/22 00:20:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.2 KB, free 424.2 MB)
21/03/22 00:20:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ip-172-31-34-242.us-east-2.compute.internal:38175 (size: 24.2 KB, free: 424.4 MB)
21/03/22 00:20:10 INFO SparkContext: Created broadcast 0 from textFile at Driver.scala:18
Exception in thread "main" java.lang.NumberFormatException: For input string: "MINIMUM_SUPPORT_VALUE"
        at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
        at java.lang.Integer.parseInt(Integer.java:580)
        at java.lang.Integer.parseInt(Integer.java:615)
        at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
        at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
        at org.Apriori.Driver$.main(Driver.scala:21)
        at org.Apriori.Driver.main(Driver.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:857)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:932)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:941)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/03/22 00:20:10 INFO SparkContext: Invoking stop() from shutdown hook
21/03/22 00:20:10 INFO SparkUI: Stopped Spark web UI at http://ip-172-31-34-242.us-east-2.compute.internal:4040
21/03/22 00:20:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/22 00:20:10 INFO MemoryStore: MemoryStore cleared
21/03/22 00:20:10 INFO BlockManager: BlockManager stopped
21/03/22 00:20:10 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/22 00:20:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/22 00:20:10 INFO SparkContext: Successfully stopped SparkContext
21/03/22 00:20:10 INFO ShutdownHookManager: Shutdown hook called
21/03/22 00:20:10 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-63cf3efa-2780-48da-aade-6ca13bd0e09e
21/03/22 00:20:10 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-a512eed3-d1b9-4b82-8e28-731756b5212f
[hadoop@ip-172-31-34-242 ~]$
