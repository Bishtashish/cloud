{\rtf1\ansi\ansicpg1252\cocoartf1671
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\margl1440\margr1440\vieww28600\viewh17500\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \CocoaLigature0 Last login: Thu Mar 28 13:10:11 on ttys000\
Ashish-MacBook-Air:~ abisht1$ sudo ssh -i ~/Desktop/Key.pem hadoop@ec2-18-222-163-102.us-east-2.compute.amazonaws.com\
Password:\
The authenticity of host 'ec2-18-222-163-102.us-east-2.compute.amazonaws.com (18.222.163.102)' can't be established.\
ECDSA key fingerprint is SHA256:1fn7CJktMDBwNJyyj3HXc9ZJODPU3omN/BvoG9hdOxU.\
Are you sure you want to continue connecting (yes/no)? ye\
Please type 'yes' or 'no': yes\
Warning: Permanently added 'ec2-18-222-163-102.us-east-2.compute.amazonaws.com,18.222.163.102' (ECDSA) to the list of known hosts.\
\
       __|  __|_  )\
       _|  (     /   Amazon Linux AMI\
      ___|\\___|___|\
\
https://aws.amazon.com/amazon-linux-ami/2018.03-release-notes/\
15 package(s) needed for security, out of 25 available\
Run "sudo yum update" to apply all updates.\
                                                                    \
EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR    \
E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R   \
EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R \
  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R\
  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R\
  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R \
  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR   \
  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R  \
  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R\
  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R\
EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R\
E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R\
EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR\
                                                                    \
[hadoop@ip-172-31-13-160 ~]$ aws s3 cp s3://ga4/AssociationActionRules.jar .\
download: s3://ga4/AssociationActionRules.jar to ./AssociationActionRules.jar\
[hadoop@ip-172-31-13-160 ~]$ hadoop jar ./AssociationActionRules.jar snippet.Main s3://ga4/attributes.txt s3://ga4/data.txt s3://ga4/parameters.txt s3://ga4/AssociationActionRulesOutput02 100 75\
21/04/02 23:21:42 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-13-160.us-east-2.compute.internal/172.31.13.160:8032\
21/04/02 23:21:44 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.\
21/04/02 23:21:44 INFO input.FileInputFormat: Total input files to process : 1\
21/04/02 23:21:44 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library\
21/04/02 23:21:44 INFO lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 1546b8dc0ca6f1ffd26a812d52bd7b80915e0a25]\
21/04/02 23:21:45 INFO mapreduce.JobSubmitter: number of splits:1\
21/04/02 23:21:45 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1553815198271_0001\
21/04/02 23:21:46 INFO impl.YarnClientImpl: Submitted application application_1553815198271_0001\
21/04/02 23:21:46 INFO mapreduce.Job: The url to track the job: http://ip-172-31-13-160.us-east-2.compute.internal:20888/proxy/application_1553815198271_0001/\
21/04/02 23:21:46 INFO mapreduce.Job: Running job: job_1553815198271_0001\
21/04/02 23:22:30 INFO mapreduce.Job: Job job_1553815198271_0001 running in uber mode : false\
21/04/02 23:22:30 INFO mapreduce.Job:  map 0% reduce 0%\
21/04/02 23:22:46 INFO mapreduce.Job:  map 100% reduce 0%\
21/04/02 23:22:56 INFO mapreduce.Job:  map 100% reduce 33%\
21/04/02 23:23:00 INFO mapreduce.Job:  map 100% reduce 67%\
21/04/02 23:23:01 INFO mapreduce.Job:  map 100% reduce 100%\
21/04/02 23:23:02 INFO mapreduce.Job: Job job_1553815198271_0001 completed successfully\
21/04/02 23:23:02 INFO mapreduce.Job: Counters: 55\
	File System Counters\
		FILE: Number of bytes read=5111\
		FILE: Number of bytes written=692453\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=82\
		HDFS: Number of bytes written=0\
		HDFS: Number of read operations=1\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=0\
		S3: Number of bytes read=13448\
		S3: Number of bytes written=478\
		S3: Number of read operations=0\
		S3: Number of large read operations=0\
		S3: Number of write operations=0\
	Job Counters \
		Killed reduce tasks=1\
		Launched map tasks=1\
		Launched reduce tasks=3\
		Data-local map tasks=1\
		Total time spent by all maps in occupied slots (ms)=593040\
		Total time spent by all reduces in occupied slots (ms)=2869440\
		Total time spent by all map tasks (ms)=12355\
		Total time spent by all reduce tasks (ms)=29890\
		Total vcore-milliseconds taken by all map tasks=12355\
		Total vcore-milliseconds taken by all reduce tasks=29890\
		Total megabyte-milliseconds taken by all map tasks=18977280\
		Total megabyte-milliseconds taken by all reduce tasks=91822080\
	Map-Reduce Framework\
		Map input records=961\
		Map output records=151\
		Map output bytes=16055\
		Map output materialized bytes=5099\
		Input split bytes=82\
		Combine input records=0\
		Combine output records=0\
		Reduce input groups=151\
		Reduce shuffle bytes=5099\
		Reduce input records=151\
		Reduce output records=4\
		Spilled Records=302\
		Shuffled Maps =3\
		Failed Shuffles=0\
		Merged Map outputs=3\
		GC time elapsed (ms)=1353\
		CPU time spent (ms)=6620\
		Physical memory (bytes) snapshot=1785352192\
		Virtual memory (bytes) snapshot=17335091200\
		Total committed heap usage (bytes)=1505755136\
	Shuffle Errors\
		BAD_ID=0\
		CONNECTION=0\
		IO_ERROR=0\
		WRONG_LENGTH=0\
		WRONG_MAP=0\
		WRONG_REDUCE=0\
	File Input Format Counters \
		Bytes Read=13448\
	File Output Format Counters \
		Bytes Written=478\
[hadoop@ip-172-31-13-160 ~]$ \
}